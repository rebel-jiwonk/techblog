<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/roots/_next/static/css/a8656e5c0df2139f.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/roots/_next/static/chunks/webpack-4b43eb43035ce4bc.js"/><script src="/roots/_next/static/chunks/4bd1b696-585253e839c2b9ee.js" async=""></script><script src="/roots/_next/static/chunks/684-4394eb5030bf06c1.js" async=""></script><script src="/roots/_next/static/chunks/main-app-1fc306bcd6011f70.js" async=""></script><script src="/roots/_next/static/chunks/874-eca35184d6cea21c.js" async=""></script><script src="/roots/_next/static/chunks/app/layout-946d77a9d4cfdf8d.js" async=""></script><title>Konan Technology &amp; Rebellions: Korean LLM Running on Korean NPU</title><meta name="description" content="Konan’s LLM now runs on Rebellions’ ATOM server in the form of the ‘Konan AI Station Server’, showcasing a successful fusion of domestic AI software and NPU hardware."/><link rel="icon" href="/roots/favicon.ico" type="image/x-icon" sizes="16x16"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/roots/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="bg-base-50 text-base-800 dark:bg-base-800 dark:text-base-50 font-sans transition-colors duration-200"><script>((e,t,r,n,o,a,i,u)=>{let l=document.documentElement,s=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&a?o.map(e=>a[e]||e):o;r?(l.classList.remove(...n),l.classList.add(a&&a[t]?a[t]:t)):l.setAttribute(e,t)}),r=t,u&&s.includes(r)&&(l.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","dark",null,["light","dark"],null,true,true)</script><div class="bg-base-50 text-base-800 dark:bg-base-800 dark:text-base-50 min-h-screen flex flex-col"><header class="border-b border-base-200 dark:border-base-700 px-6 py-4 flex items-center justify-between"><a class="text-lg font-bold uppercase" href="/roots/">REBELLIONS TECHBLOG</a><div class="flex items-center gap-4"><button class="uppercase tracking-wide px-4 py-2 bg-[#52F756] text-black font-mono font-bold border border-[#1B1F23] hover:opacity-90">한국어</button></div></header><main class="max-w-5xl mx-auto px-6 py-12 flex-grow"><article class="prose prose-lg max-w-none text-base-800 dark:text-base-50"><h1>Konan Technology &amp; Rebellions: Korean LLM Running on Korean NPU</h1><p class="text-sm text-base-500">2024-06-09</p><p>Korean AI software company <strong>Konan Technology</strong> has announced the deployment of its large language model (LLM) on <strong>Rebellions&#x27; NPU-based ATOM server</strong>, integrated as the <strong>&quot;Konan AI Station Server.&quot;</strong></p>
<p>This integration marks a significant milestone in combining Korea’s homegrown AI software and semiconductor capabilities. The two companies have been collaborating since August last year under a joint R&amp;D agreement to merge AI models with cutting-edge AI hardware.</p>
<p>According to Konan, their LLM runs smoothly on the ATOM server and is currently undergoing further optimization with Rebellions.</p>
<p>The <strong>Konan AI Station Server</strong> is designed as an on-premise generative AI infrastructure for team or organization-wide use. Its flexible architecture allows users to scale GPU, memory, and storage depending on demand. Operating fully offline, it is particularly well-suited for security-sensitive environments.</p>
<p>A Konan representative emphasized, “By demonstrating that a Korean LLM can run natively on a Korean NPU, we&#x27;ve validated the potential for domestic technology to lead in the AI market.”</p>
<p>Konan also revealed plans to participate in the <strong>World Best LLM (WBL)</strong> national AI development initiative.</p></article><!--$--><!--/$--><!--$--><!--/$--></main><footer class="border-t border-base-200 dark:border-base-700 mt-24 py-8 text-center text-sm text-base-500 dark:text-base-400">© <!-- -->2025<!-- --> TECHBLOG</footer></div><script src="/roots/_next/static/chunks/webpack-4b43eb43035ce4bc.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[4970,[],\"ClientSegmentRoot\"]\n3:I[5636,[\"874\",\"static/chunks/874-eca35184d6cea21c.js\",\"177\",\"static/chunks/app/layout-946d77a9d4cfdf8d.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n8:I[9665,[],\"MetadataBoundary\"]\na:I[9665,[],\"OutletBoundary\"]\nd:I[4911,[],\"AsyncMetadataOutlet\"]\nf:I[9665,[],\"ViewportBoundary\"]\n11:I[6614,[],\"\"]\n:HL[\"/roots/_next/static/css/a8656e5c0df2139f.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"pqnMPZVgQqgIgPV80LZV3\",\"p\":\"/roots\",\"c\":[\"\",\"en\",\"blog\",\"konan-llm.en\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"en\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"konan-llm.en\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/roots/_next/static/css/a8656e5c0df2139f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"Component\":\"$3\",\"slots\":{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]},\"params\":{},\"promise\":\"$@6\"}]]}],{\"children\":[\"en\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"konan-llm.en\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"W-MfdOGMHSqZ4mS-RRAkF\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:\"$Sreact.suspense\"\n13:I[4911,[],\"AsyncMetadata\"]\n6:{}\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"article\",null,{\"className\":\"prose prose-lg max-w-none text-base-800 dark:text-base-50\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"Konan Technology \u0026 Rebellions: Korean LLM Running on Korean NPU\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-base-500\",\"children\":\"2024-06-09\"}],[[\"$\",\"p\",\"p-0\",{\"children\":[\"Korean AI software company \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"Konan Technology\"}],\" has announced the deployment of its large language model (LLM) on \",[\"$\",\"strong\",\"strong-1\",{\"children\":\"Rebellions' NPU-based ATOM server\"}],\", integrated as the \",[\"$\",\"strong\",\"strong-2\",{\"children\":\"\\\"Konan AI Station Server.\\\"\"}]]}],\"\\n\",[\"$\",\"p\",\"p-1\",{\"children\":\"This integration marks a significant milestone in combining Korea’s homegrown AI software and semiconductor capabilities. The two companies have been collaborating since August last year under a joint R\u0026D agreement to merge AI models with cutting-edge AI hardware.\"}],\"\\n\",[\"$\",\"p\",\"p-2\",{\"children\":\"According to Konan, their LLM runs smoothly on the ATOM server and is currently undergoing further optimization with Rebellions.\"}],\"\\n\",[\"$\",\"p\",\"p-3\",{\"children\":[\"The \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"Konan AI Station Server\"}],\" is designed as an on-premise generative AI infrastructure for team or organization-wide use. Its flexible architecture allows users to scale GPU, memory, and storage depending on demand. Operating fully offline, it is particularly well-suited for security-sensitive environments.\"]}],\"\\n\",[\"$\",\"p\",\"p-4\",{\"children\":\"A Konan representative emphasized, “By demonstrating that a Korean LLM can run natively on a Korean NPU, we've validated the potential for domestic technology to lead in the AI market.”\"}],\"\\n\",[\"$\",\"p\",\"p-5\",{\"children\":[\"Konan also revealed plans to participate in the \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"World Best LLM (WBL)\"}],\" national AI development initiative.\"]}]]]}]\n"])</script><script>self.__next_f.push([1,"14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Konan Technology \u0026 Rebellions: Korean LLM Running on Korean NPU\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Konan’s LLM now runs on Rebellions’ ATOM server in the form of the ‘Konan AI Station Server’, showcasing a successful fusion of domestic AI software and NPU hardware.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/roots/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]],\"error\":null,\"digest\":\"$undefined\"}\ne:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>