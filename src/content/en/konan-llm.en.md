---
title: "Konan Technology & Rebellions: Korean LLM Running on Korean NPU"
slug: "konan-rebellions-llm"
description: "Konan’s LLM now runs on Rebellions’ ATOM server in the form of the ‘Konan AI Station Server’, showcasing a successful fusion of domestic AI software and NPU hardware."
date: "2024-06-09"
lang: "en"
authors: ["Kong Tae-jun"]
tags: ["Solution"]
---

Korean AI software company **Konan Technology** has announced the deployment of its large language model (LLM) on **Rebellions' NPU-based ATOM server**, integrated as the **"Konan AI Station Server."**

This integration marks a significant milestone in combining Korea’s homegrown AI software and semiconductor capabilities. The two companies have been collaborating since August last year under a joint R&D agreement to merge AI models with cutting-edge AI hardware.

According to Konan, their LLM runs smoothly on the ATOM server and is currently undergoing further optimization with Rebellions.

The **Konan AI Station Server** is designed as an on-premise generative AI infrastructure for team or organization-wide use. Its flexible architecture allows users to scale GPU, memory, and storage depending on demand. Operating fully offline, it is particularly well-suited for security-sensitive environments.

A Konan representative emphasized, “By demonstrating that a Korean LLM can run natively on a Korean NPU, we've validated the potential for domestic technology to lead in the AI market.”

Konan also revealed plans to participate in the **World Best LLM (WBL)** national AI development initiative.